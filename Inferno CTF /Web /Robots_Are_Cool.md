# Challenge "Robots Are Cool"

<img width="496" height="567" alt="image" src="https://github.com/user-attachments/assets/bbb7da6f-3c15-4325-91e2-45b7a72bddc1" />

____________________________________________________________
- Host locally with Docker:

<img width="1900" height="236" alt="image" src="https://github.com/user-attachments/assets/d1ba9fec-d1ec-4c3a-9ea6-e8151d0df7e6" />


- Access the website locally at `localhost:8080` :

<img width="688" height="154" alt="image" src="https://github.com/user-attachments/assets/ee4925a3-03ab-4789-99d1-21ebacc665e8" />

- Lets check `localhost:8080/robots.txt` :

Think of the internet as a giant city, and websites are the buildings. Search engines like Google have robots (also called crawlers) that go around visiting every building to see whatâ€™s inside so they can show it in search results.

`/robots.txt` is just a file at the front of a website that tells these robots:

- Where they can go (like â€œthis door is openâ€ ğŸšª)
 
- Where they shouldnâ€™t go (like â€œplease donâ€™t go in this doorâ€ ğŸš«)
______________________________________________

- On our Case let's access `localhost:8080/robots.txt` :

<img width="300" height="54" alt="image" src="https://github.com/user-attachments/assets/895d4e7a-e2f7-48d5-9a30-8f8d97bcb0cd" />

Flag : `flag{r0b0t5_4r3_c00000l_r1ght}`

- Let's access now as we saw in the picture that hidden Directory at http://localhost:8080/supersecretpage.html :

<img width="424" height="143" alt="image" src="https://github.com/user-attachments/assets/33f1ee0b-4304-4386-b59b-e2fe2afab798" />

